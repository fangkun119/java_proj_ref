{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57c8931f-7a30-4a91-bc04-f49cfaf11cfa",
   "metadata": {},
   "source": [
    "# <center> 一 LangGraph底层原理与入门实践"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d79f932-5f3b-4ebe-8cea-09fc58315f25",
   "metadata": {},
   "source": [
    "## 1. Agent概述"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09d4660-8dae-4501-97db-fc58ae3225d5",
   "metadata": {},
   "source": [
    "### 1.1 Agent开发当前尬尴的局面"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e584b2b2-9595-4883-b3b5-d137bf86eb1b",
   "metadata": {},
   "source": [
    "Agent基本原理回顾"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a318f521-5ef9-4a97-9796-feca2076c14a",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"../pic/lesson01/1.jpg\" width=80%> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f59f75-7cfd-482d-9a4d-39424cf176fb",
   "metadata": {},
   "source": [
    "Agent开发的模型支持和工具支持"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e5bffd-12a2-4a66-ada5-0519f493978f",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"..//pic/lesson01/2.jpg\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf4dbbb-6ae9-47cb-8922-c7121964a373",
   "metadata": {},
   "source": [
    "### 1.2 Agent开发框架哪个好？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d123d1-da36-462d-87c9-32a4046f8042",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"../pic/lesson01/3.jpg\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b445e3-4d4e-4b48-9d9e-609bf1582511",
   "metadata": {},
   "source": [
    "LangGraph虽然学习曲线高，但是也是对底层的Agent开发框架，学好这个框架，有利于大家学习其余的任何Agent开发框架，就像\n",
    "《倚天屠龙记》里面张无忌练了九阳神功以后，他在学习其它武功都很快！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9346b74-1436-4bbc-9680-9665a3e4624a",
   "metadata": {},
   "source": [
    "### 1.3 学习Agent开发框架的8大要点"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5d6ba1-7c95-4ae5-8bc7-c1c7063eed37",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"..//pic/lesson01/4.jpg\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0777d653-c7d5-4b78-930a-8e9c5c75fbe1",
   "metadata": {},
   "source": [
    "## 2. LangGraph底层原理介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c9c1ec-54b0-410d-9163-dd65a72bd777",
   "metadata": {},
   "source": [
    "&emsp;&emsp;LangGraph 是一个功能强大且通用性广泛的 AI Agent 开发框架。在**大语言模型的支持方面**，LangGraph 不仅兼容 GPT 系列模型，还支持包括 glm、llama 和 Qwen 在内的多种热门在线和开源模型，几乎涵盖了当前主流的大模型选项，为开发者提供了丰富的选择。关于**大模型的接入方式**，开发者可以采用传统的集成方式，例如通过 openai API 将大模型接入到 LangGraph 的 AI Agent 开发流程中，也可以借助 ollma 和 vllm 等大模型推理加速库，以实现更高效、便捷的集成。除此之外，在 AI Agent 的**构建范式方面**，LangGraph 不仅内置了支持 ReAct 框架的预配置代理机制，还允许灵活扩展更多自定义策略，例如 Planning 策略，以满足不同场景的需求。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48c7bde-80ba-4d4f-a172-912e64b159a4",
   "metadata": {},
   "source": [
    "&emsp;&emsp;综合这三方面来看，`LangGraph` 的**高度自主性和开放性**确实使其在功能和灵活性上相比 `其它Agent开发框架` 更具优势。然而，这种自主性和可扩展性也带来了更高的复杂性和开发成本。选择使用 `LangGraph` 意味着 **开发者需要承担更多的自主开发任务**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7635501-8007-44dc-a0b6-1fe4cb7add52",
   "metadata": {},
   "source": [
    "&emsp;&emsp;**那么`LangGraph`到底是什么呢？**\n",
    "\n",
    "&emsp;&emsp;从名称来看，`LangGraph` 与 `LangChain` 有着密切的关联，而这在实际上也确实如此。**`LangGraph` 是一个基于 `LangChain` 表达式语言构建的框架，专用于开发 `AI Agent`。** 因此，`LangGraph` 在大模型支持、接入以及 `AI Agent` 构建方面的优势，可以直接从 `LangChain` 的功能中自然继承。 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc173fb2-8113-48b1-9ded-0ac3be4f3341",
   "metadata": {},
   "source": [
    "&emsp;&emsp;`LangChain`发展至现在，仍然是构建大语言模型应用程序的前沿框架之一。特别是在最新发布的`v0.3`版本中，已经基本完成了由传统类到表达式语言(LCEL)的重要过渡，给开发者带来的直接利好就是**定义和执行分步操作序列（也称为链）会更加简单**。用更专业的术语来说，**使用`LangChain` 构建的是 DAG（有向无环图）**。而之所以会出现`LangGraph`框架，根本原因是在于随着AI应用（特别是AI Agent）的发展，**对于大语言模型的使用不仅仅是作为执行工具，而更多作为推理引擎的需求在日益增长**。这种转变带来的是更多的重复（循环）和复杂条件的交互需求，这就导致**基于`LCEL`的线性序列构建方式在构建更复杂、更智能的系统时显示出了明显的局限性。**如下所示的代码就是在`LangChain`中通过`LECL`表达式语言构建`Chain`的一种最简单的方式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aefd41f6-c3d7-40ff-9fe1-4e38b1782450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Collecting langchain==0.3.3\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/92/82/c17abaa44074ec716409305da4783f633b0eb9b09bb28ed5005220269bdb/langchain-0.3.3-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /root/miniconda3/lib/python3.12/site-packages (from langchain==0.3.3) (6.0.2)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain==0.3.3)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/8a/ab/81d4514527c068670cb1d7ab62a81a185df53a7c379bd2a5636e83d09ede/SQLAlchemy-2.0.36-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp<4.0.0,>=3.8.3 (from langchain==0.3.3)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/40/7f/6de218084f9b653026bd7063cd8045123a7ba90c25176465f266976d8c82/aiohttp-3.11.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting langchain-core<0.4.0,>=0.3.10 (from langchain==0.3.3)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/95/4f/fe1de63f6fc1ac7af3ba4ae12d420af1a19f7893b5fcb72856b9fc67f650/langchain_core-0.3.29-py3-none-any.whl (411 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain==0.3.3)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/4b/83/f8081c3bea416bd9d9f0c26af795c74f42c24f9ad3c4fbf361b7d69de134/langchain_text_splitters-0.3.5-py3-none-any.whl (31 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.3.3)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/de/f0/63b06b99b730b9954f8709f6f7d9b8d076fa0a973e472efe278089bde42b/langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numpy<2.0.0,>=1.26.0 (from langchain==0.3.3)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/0f/50/de23fde84e45f5c4fda2488c759b69990fd4512387a8632860f3ac9cd225/numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /root/miniconda3/lib/python3.12/site-packages (from langchain==0.3.3) (2.10.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /root/miniconda3/lib/python3.12/site-packages (from langchain==0.3.3) (2.31.0)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain==0.3.3)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/d2/3f/8ba87d9e287b9d385a02a7114ddcef61b26f86411e121c9003eb509a1773/tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.3)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/b9/74/fbb6559de3607b3300b9be3cc64e97548d55678e44623db17820dbd20002/aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.3)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/ec/6a/bc7e17a3e87a2985d3e8f4da4cd0f481060eb78fb08596c42be62c90a4d9/aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/miniconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.3) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.3)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/af/f2/64b73a9bb86f5a89fb55450e97cd5c1f84a862d4ff90d9fd1a73ab0f64a5/frozenlist-1.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (283 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.6/283.6 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.3)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/d3/c8/529101d7176fe7dfe1d99604e48d69c5dfdcadb4f06561f465c8ef12b4df/multidict-6.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (131 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.0/131.0 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.3)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/1c/07/ebe102777a830bca91bbb93e3479cd34c2ca5d0361b83be9dbd93104865e/propcache-0.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (243 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.6/243.6 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.3)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/1a/e1/a097d5755d3ea8479a42856f51d97eeff7a3a7160593332d98f2709b3580/yarl-1.18.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (336 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.9/336.9 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jsonpatch<2.0,>=1.33 in /root/miniconda3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.10->langchain==0.3.3) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /root/miniconda3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.10->langchain==0.3.3) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /root/miniconda3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.10->langchain==0.3.3) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /root/miniconda3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.3) (0.27.2)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain==0.3.3)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/48/90/e583d6e29937ec30a164f1d86a0439c1a2477b5aae9f55d94b37a4f5b5f0/orjson-3.10.13-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (131 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain==0.3.3)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/3f/51/d4db610ef29373b879047326cbf6fa98b6c1969d6f6dc423279de2b1be2c/requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /root/miniconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.3) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /root/miniconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.3) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain==0.3.3) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain==0.3.3) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain==0.3.3) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain==0.3.3) (2024.2.2)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain==0.3.3)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/f1/66/033e58a50fd9ec9df00a8671c74f1f3a320564c6415a4ed82a1c651654ba/greenlet-3.1.1-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (613 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m613.1/613.1 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio in /root/miniconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.3) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in /root/miniconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.3) (1.0.7)\n",
      "Requirement already satisfied: sniffio in /root/miniconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.3) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /root/miniconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.3) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /root/miniconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.10->langchain==0.3.3) (2.1)\n",
      "Installing collected packages: tenacity, propcache, orjson, numpy, multidict, greenlet, frozenlist, aiohappyeyeballs, yarl, SQLAlchemy, requests-toolbelt, aiosignal, langsmith, aiohttp, langchain-core, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.3\n",
      "    Uninstalling numpy-2.1.3:\n",
      "      Successfully uninstalled numpy-2.1.3\n",
      "Successfully installed SQLAlchemy-2.0.36 aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 frozenlist-1.5.0 greenlet-3.1.1 langchain-0.3.3 langchain-core-0.3.29 langchain-text-splitters-0.3.5 langsmith-0.1.147 multidict-6.1.0 numpy-1.26.4 orjson-3.10.13 propcache-0.2.1 requests-toolbelt-1.0.0 tenacity-8.5.0 yarl-1.18.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Collecting langchain-openai\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/ed/54/63c8264d7dbc3bf31ba61bf97740fdd76386b2d4f9a58f58afd3961ce7d7/langchain_openai-0.2.14-py3-none-any.whl (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: langchain-core<0.4.0,>=0.3.27 in /root/miniconda3/lib/python3.12/site-packages (from langchain-openai) (0.3.29)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /root/miniconda3/lib/python3.12/site-packages (from langchain-openai) (1.59.3)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/26/32/e0e3a859136e95c85a572e4806dc58bf1ddf651108ae8b97d5f3ebe1a244/tiktoken-0.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /root/miniconda3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /root/miniconda3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /root/miniconda3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (0.1.147)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /root/miniconda3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /root/miniconda3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (2.10.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /root/miniconda3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /root/miniconda3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /root/miniconda3/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /root/miniconda3/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /root/miniconda3/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /root/miniconda3/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /root/miniconda3/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /root/miniconda3/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.66.2)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/fb/13/e3b075031a738c9598c51cfbc4c7879e26729c53aa9cca59211c44235314/regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /root/miniconda3/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.31.0)\n",
      "Requirement already satisfied: idna>=2.8 in /root/miniconda3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai) (3.7)\n",
      "Requirement already satisfied: certifi in /root/miniconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /root/miniconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /root/miniconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /root/miniconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain-openai) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /root/miniconda3/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-openai) (3.10.13)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /root/miniconda3/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /root/miniconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.27->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /root/miniconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.27->langchain-openai) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.1.0)\n",
      "Installing collected packages: regex, tiktoken, langchain-openai\n",
      "Successfully installed langchain-openai-0.2.14 regex-2024.11.6 tiktoken-0.8.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    " ! pip install langchain==0.3.3\n",
    " ! pip install langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3af14e7-4037-47af-a012-190fc878b66f",
   "metadata": {},
   "source": [
    "> LangChain ChatOpenAI：https://python.langchain.com/docs/integrations/chat/openai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da1ae585-0405-4394-b36c-79ae1643a53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "key=\"sk-DWtZI5R2tOWLYiREfzzsD7Z3XEsEH5n6SClKqZ4Lxr5GcMA\"\n",
    "base_url=\"https://chatapi.littlewheat.com/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e5ba765-f84f-4eee-b199-4f6041c8c642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='我喜欢编程。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 26, 'total_tokens': 31, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f3927aa00d', 'finish_reason': 'stop', 'logprobs': None}, id='run-930fad1c-05ac-41ad-9aef-8586ea61f955-0', usage_metadata={'input_tokens': 26, 'output_tokens': 5, 'total_tokens': 31, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", api_key=key,base_url=base_url)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant that translates {input_language} to {output_language}.\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"Chinese\",\n",
    "        \"input\": \"I love programming.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682eaff7-f569-42a9-9124-8bb45435066d",
   "metadata": {},
   "source": [
    "&emsp;&emsp;反观`LangGraph`，顾名思义，`LangGraph` 在图这个概念上有很大的侧重，它的出现就是`要解决线性序列的局限性问题，而解决的方法就是循环图`。在`LangGraph`框架中，**用图来管理代理的生命周期并在其状态内将暂存器作为消息进行跟踪，增加了以循环方式跨各种计算步骤协调多个链或参与者的功能。**这就与 `LangChain` 将代理视为可以附加工具和插入某些提示的对象不同，对于图来说，意味着**我们可以从任何可运行的功能或代理或链作为一个程序的起点。**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0b7ee0-4149-4ae1-a4df-ec6f677e5a68",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d9e2a9c-c35a-450a-b82c-210384f14c1f",
   "metadata": {},
   "source": [
    "&emsp;&emsp;`LangGraph`通过组合`Nodes`和`Edges`去创建复杂的循环工作流程，通过消息传递的方式串联所有的节点形成一个通路。**那么维持消息能够及时的更新并向该去的地方传递，则依赖`langGraph`构建的`State`概念。** 在`LangGraph`构建的流程中，每次执行都会启动一个状态，图中的节点在处理时会传递和修改该状态。这个状态不仅仅是一组静态数据，而是由每个节点的输出动态更新，然后影响循环内的后续操作。如下所示：👇"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac7368d-0d1b-46d2-a90d-acdace0006b9",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"../pic/lesson01/7.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98f08ea-006e-4428-831c-60c5bb9d1aa6",
   "metadata": {},
   "source": [
    "&emsp;&emsp;**此谓共享状态。**共享状态是指在执行期间在图内的节点之间传递的数据或信息**。 `LangGraph`允许节点在图上执行时时通过共享和更新此公共状态来进行交互。**这种共享状态使节点能够根据它们共同维护的数据进行通信、交换信息并影响彼此的行为。通过利用共享状态， `LangGraph`才能够促进节点间操作的协调和同步，允许动态交互和创建复杂的工作流程，其中节点可以协作并根据可用的共享信息做出决策。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b2000f-52a5-4daf-84f1-88fb20f5d545",
   "metadata": {},
   "source": [
    "&emsp;&emsp;从`LangGraph`官方的定义看，该框架是一个**用于使用大模型构建有状态、多参与者应用程序的库，可以创建代理和多代理工作流程**。而其官方自己总结的`LangGraph`的优势则是：\n",
    "\n",
    "- **循环和分支**：在应用程序中实现循环和条件。\n",
    "- **持久性**：在图中的每个步骤之后自动保存状态。随时暂停和恢复图形执行，以支持错误恢复、人机交互工作流程等。\n",
    "- **人机交互**：中断图形执行以批准或编辑代理计划的下一个操作。\n",
    "- **流支持**：流输出由每个节点生成（包括令牌流）。\n",
    "- **与 LangChain 集成**：LangGraph 与LangChain和LangSmith无缝集成（但不需要它们）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34921e3f-ccdb-4d3f-8b50-29775d3371ba",
   "metadata": {},
   "source": [
    "> LangGraph Github：https://github.com/langchain-ai/langgraph\n",
    ">\n",
    "> LangGraph Docs：https://langchain-ai.github.io/langgraph/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ea573e-6b48-4b1a-a9b7-0450bda19e20",
   "metadata": {},
   "source": [
    "&emsp;&emsp;至此，当我们了解了上述的原理后，再来看`LangGraph`官方的介绍，就能够比较清楚的理解其独特优势究竟体现在何处。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fa8045-09a6-4650-81ae-169d277b51c9",
   "metadata": {},
   "source": [
    "## 3. LangGraph底层源码解析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9979e7-2b90-46fd-9c09-32554853b4ce",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在上一小节的原理介绍部分，我们在图中提到了节点、边、状态和路由四个概念，那在`LangGraph`框架中，各个组件是怎么实现，以及如何定义图结构呢？ 我们将在这一小节展开详细的介绍和代码实践。首先我们来看图。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401e65e2-fcdb-4bd7-b509-7e9ec5f8397d",
   "metadata": {},
   "source": [
    "### 3.1 Graph基类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d43963-94bb-4900-a452-c40aa769cbea",
   "metadata": {},
   "source": [
    "&emsp;&emsp;对于任意一个简单或者复杂的图来说，都是基于`Graph`类来构建和管理图结构的。在`Graph`类中允许添加节点、边，并定义节点间的动态流转逻辑。如下是`Graph`类的主要组成部分和功能："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a203ec6-cd27-43d8-9edd-82f97f7325fa",
   "metadata": {},
   "source": [
    "> Class Graph ：https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.graph.Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db87967-6806-4f04-a173-962356ef746c",
   "metadata": {},
   "source": [
    "```python\n",
    "from collections import defaultdict\n",
    "from typing import Any, Callable, Dict, Optional, Set, Tuple, Union, Awaitable, Hashable\n",
    "\n",
    "class Graph:\n",
    "    def __init__(self) -> None:\n",
    "        self.nodes: Dict[str, Any] = {}  # 一个字典，用于存储图中的所有节点。每个节点可以是一个字符串标识或者是一个可调用对象\n",
    "        self.edges: Set[Tuple[str, str]] = set()  # 一个集合，用来存储图中所有的边，边由一对节点名称组成，表示从一个节点到另一个节点的直接连接。\n",
    "        self.branches: defaultdict = defaultdict(dict)  # 一个默认字典，用于存储条件分支，允许从一个节点根据特定条件转移到多个不同的节点。\n",
    "        self.support_multiple_edges = False  # 一个布尔值，指示图是否支持同一对节点间的多条边。\n",
    "        self.compiled = False    #  一个布尔值，表示图是否已经被编译。编译是指图的结构已经设置完毕，准备进行执行。\n",
    "\n",
    "    @property\n",
    "    def _all_edges(self) -> Set[Tuple[str, str]]:\n",
    "        \"\"\"\n",
    "        获取所有的边的信息。\n",
    "        \"\"\"\n",
    "        return self.edges\n",
    "\n",
    "    def add_node(self, node: Union[str, Callable], action: Optional[Callable] = None, *, metadata: Optional[Dict[str, Any]] = None) -> 'Graph':\n",
    "        \"\"\"\n",
    "        添加一个新节点到图中。节点可以有附加的元数据，这些元数据存储在节点的字典中。\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def add_edge(self, start_key: str, end_key: str) -> 'Graph':\n",
    "        \"\"\"\n",
    "        在图中添加一条边，连接两个指定的节点。\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def add_conditional_edges(self, source: str, path: Callable, path_map: Optional[Dict[Hashable, str]] = None, then: Optional[str] = None) -> 'Graph':\n",
    "        \"\"\"\n",
    "        添加一个条件边，允许在执行时根据某个条件从一个节点动态地转移到一个或多个节点。\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def set_entry_point(self, key: str) -> 'Graph':\n",
    "        \"\"\"\n",
    "        设置图的入口点，即定义图执行的起始节点。\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def set_conditional_entry_point(self, path: Callable, path_map: Optional[Dict[Hashable, str]] = None, then: Optional[str] = None) -> 'Graph':\n",
    "        \"\"\"\n",
    "        设置一个条件入口点，允许根据条件动态决定图的起始执行点。\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def set_finish_point(self, key: str) -> 'Graph':\n",
    "        \"\"\"\n",
    "        设置结束点，定义图执行到此节点时将停止。\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def validate(self, interrupt: Optional[Set[str]] = None) -> 'Graph':\n",
    "        \"\"\"\n",
    "        验证图的结构是否正确，确保所有节点和边的定义都符合逻辑和图的规则。\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def compile(self, checkpointer=None, interrupt_before: Optional[Set[str]] = None, interrupt_after: Optional[Set[str]] = None, debug: bool = False) -> 'Graph':\n",
    "        \"\"\"\n",
    "        编译图，确认图的结构合法且可执行后，准备图以供执行。\n",
    "        \"\"\"\n",
    "        pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2c12b0-7d96-4eb6-8e65-f63b251aebcf",
   "metadata": {},
   "source": [
    "&emsp;&emsp;从源码中可以看出，`Graph`该类提供了丰富的方法来控制图的编译和执行，使其适用于需要复杂逻辑和流程控制的应用场景。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ecfab3-8598-4b66-804e-ac575ae4ac43",
   "metadata": {},
   "source": [
    "## 3.2 GraphState"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4a4e40-1d76-4344-964f-9c519581d25d",
   "metadata": {},
   "source": [
    "&emsp;&emsp;定义图时要做的第一件事是定义图的`State`。状态表示会随着图计算的进行而维护和更新的上下文或记忆。它用来确保图中的每个步骤都可以访问先前步骤的相关信息，从而可以根据整个过程中积累的数据进行动态决策。这个过程通过状态图`StateGraph`类实现，它继承自 `Graph` 类，这意味着 `StateGraph` 会使用或扩展基类的属性和方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df88c585-ab98-4458-adcb-e82a5b0ce949",
   "metadata": {},
   "source": [
    "> Class StateGraph：https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.state.StateGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498851a7-7e1a-47c0-8b02-31355593b9af",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "from collections import defaultdict\n",
    "from typing import Any, Callable, Dict, Optional, Set, Tuple, Type, Union\n",
    "\n",
    "class StateGraph(Graph):\n",
    "\n",
    "    \"\"\"StateGraph 是一个管理状态并通过定义的输入和输出架构支持状态转换的图。\"\"\"\n",
    "    def __init__(self, state_schema: Optional[Type[Any]] = None, config_schema: Optional[Type[Any]] = None) -> None:\n",
    "        super().__init__()\n",
    "        self.state_schema = state_schema      # 一个可选的类型参数，定义图状态的结构。这是用于定义和验证图中节点处理的状态数据的模式。\n",
    "        self.config_schema = config_schema    # 一个可选的类型参数，用于定义配置的结构。这可以用于定义和验证图的配置参数。\n",
    "        input: Optional[Type[Any]] = None,   # 消息输入\n",
    "        output: Optional[Type[Any]] = None, # 消息输出\n",
    "\n",
    "    def add_node(self, node: Union[str, Callable], action: Optional[Callable] = None, *, metadata: Optional[Dict[str, Any]] = None) -> 'StateGraph':\n",
    "        \"\"\"向图中添加一个新节点。节点可以是一个具名字符串或一个可调用对象（如函数）, 如果node是字符串，则action应为与节点关联的可调用动作。\"\"\"\n",
    "        pass\n",
    "\n",
    "    def add_edge(self, start_key: str, end_key: str) -> 'StateGraph':\n",
    "        \"\"\"在图中添加一条边，连接两个节点。\"\"\"\n",
    "        pass\n",
    "\n",
    "    def compile(self) -> 'CompiledStateGraph':\n",
    "        \"\"\"编译图，将其转换成可运行的形式。包括验证图的完整性、预处理数据等。\"\"\"\n",
    "        pass\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392577f9-8ebb-4406-adba-f0c9d652c176",
   "metadata": {},
   "source": [
    "- **什么是图的模式**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a3fb97-11e3-4c7a-bf70-c743ba8285b3",
   "metadata": {},
   "source": [
    "&emsp;&emsp;默认情况下，`StateGraph`使用单模式运行，这意味着在图中的任意阶段都会读取和写入相同的状态通道，所有节点都使用该状态通道进行通信。除此之外，在某些情况下如果希望对图的状态有更多的控制，比如：\n",
    "\n",
    "- 内部节点可以传递图的输入/输出中不需要的信息。\n",
    "- 对图使用不同的输入/输出模式。例如，输出可能仅包含单个相关输出键。\n",
    "\n",
    "&emsp;&emsp;`LangGraph`的底层实现上提供了多种不同图模式的支持，这可以通过`state_schema`来进行灵活的指定。不过关于自定义的图模式，因为涉及到更多的基础概念，我们将在课程的后半部分在展开详细的介绍。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569fc2b8-6214-4c5a-b967-5b6c1f6af6fd",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先来看图的单模式。任何模式都包含输入和输出，输入模式需要确保提供的输入与预期结构匹配，而输出模式根据定义的输出模式过滤内部数据以仅返回相关信息。而这个预期结构的校验，由`TypedDict`工具来限定。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2b4b36-0dc9-486f-ba02-14eacddc4201",
   "metadata": {},
   "source": [
    "- **TypeDict** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcbd87e-89b6-47b4-9396-01f9499af138",
   "metadata": {},
   "source": [
    "&emsp;&emsp;`TypedDict` 是 `Python` 类型注解系统中的一个工具，它**允许为字典中的键指定期望的具体类型**。在 `Python` 的 `typing` 模块中定义，通常用于增强代码的可读性和安全性，特别是在字典对象结构固定且明确时。示例代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a16d45d-65c2-4510-8328-7cf4c1802f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending email to Lilei at Lilei@qq.com\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "class Contact(TypedDict):\n",
    "    name: str\n",
    "    email: str\n",
    "    phone: str\n",
    "\n",
    "def send_email(contact: Contact) -> None:\n",
    "    print(f\"Sending email to {contact['name']} at {contact['email']}\")\n",
    "\n",
    "# 使用定义好的 TypedDict 创建字典\n",
    "contact_info: Contact = {\n",
    "    'name': 'Lilei',\n",
    "    'email': 'Lilei@qq.com',\n",
    "    'phone': '15814023435'\n",
    "}\n",
    "\n",
    "send_email(contact_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7689914-f724-4815-9817-2a0bf1ea423c",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在这个示例中，`Contact` 类型定义了三个必须的字段：`name`，`email`，和 `phone`，每个字段都是字符串（Str）形式。当创建 `contact_info` 字典时，必须提供所有这些字段。函数 `send_email` 则利用这个类型安全的字典进行操作。这样的 `TypedDict` 使用场景非常适合那些需要确保字典中具有特定字段和类型的应用场景，如处理从外部API返回的数据或者在内部各个模块间传递复杂的数据结构，因为在`LangGraph`图中，每个节点传递到下一个节点的数据，将直接影响到下一个节点能否顺利执行。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa22bd03-9bd4-4564-96ce-885ec8cd3bd5",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来我们实践在`LangGraph`中通过`Typedict`定义单输入输出模式。首先，需要安装所需的依赖包，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa9a9a5d-d193-49ba-91aa-16d53a9682e3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Collecting langgraph==0.2.60\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/93/ce/150789d181ea0570112c6fae330f477aa5f68fa425098c25c2c9b1556676/langgraph-0.2.60-py3-none-any.whl (135 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.7/135.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in /root/miniconda3/lib/python3.12/site-packages (from langgraph==0.2.60) (0.3.29)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.4 (from langgraph==0.2.60)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/d8/63/b2ecb322ffc978e6bcf27e3786a0efa3142c57d58daeb4e4397196117030/langgraph_checkpoint-2.0.9-py3-none-any.whl (37 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph==0.2.60)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/b3/88/95ca5e3ca12659c2d2c26d64c5e481f1fca28b3053e15f5f0aafb3cc5244/langgraph_sdk-0.1.48-py3-none-any.whl (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m814.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /root/miniconda3/lib/python3.12/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.60) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /root/miniconda3/lib/python3.12/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.60) (1.33)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /root/miniconda3/lib/python3.12/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.60) (0.1.147)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /root/miniconda3/lib/python3.12/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.60) (23.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /root/miniconda3/lib/python3.12/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.60) (2.10.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /root/miniconda3/lib/python3.12/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.60) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /root/miniconda3/lib/python3.12/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.60) (4.12.2)\n",
      "Collecting msgpack<2.0.0,>=1.1.0 (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph==0.2.60)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/f1/54/65af8de681fa8255402c80eda2a501ba467921d5a7a028c9c22a2c2eedb5/msgpack-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (401 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.4/401.4 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /root/miniconda3/lib/python3.12/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.60) (0.27.2)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /root/miniconda3/lib/python3.12/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.60) (3.10.13)\n",
      "Requirement already satisfied: anyio in /root/miniconda3/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.60) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in /root/miniconda3/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.60) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /root/miniconda3/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.60) (1.0.7)\n",
      "Requirement already satisfied: idna in /root/miniconda3/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.60) (3.7)\n",
      "Requirement already satisfied: sniffio in /root/miniconda3/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.60) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /root/miniconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.60) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /root/miniconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.60) (2.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /root/miniconda3/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.60) (2.31.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /root/miniconda3/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.60) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /root/miniconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.60) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /root/miniconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.60) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.60) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.60) (2.1.0)\n",
      "Installing collected packages: msgpack, langgraph-sdk, langgraph-checkpoint, langgraph\n",
      "Successfully installed langgraph-0.2.60 langgraph-checkpoint-2.0.9 langgraph-sdk-0.1.48 msgpack-1.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    " ! pip install langgraph==0.2.60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85a5ba7b-ca33-44ec-9a22-992de56916bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "# 定义输入的模式\n",
    "class InputState(TypedDict):\n",
    "    question: str\n",
    "\n",
    "\n",
    "# 定义输出的模式\n",
    "class OutputState(TypedDict):\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# 将 InputState 和 OutputState 这两个 TypedDict 类型合并成一个字典类型。\n",
    "class OverallState(InputState, OutputState):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac87f960-abce-4b88-99bb-aa16dd3fdd3a",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来，创建一个 `StateGraph` 对象，使用 `OverallState` 作为其状态定义，同时指定了输入和输出类型分别为 `InputState` 和 `OutputState`，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2605df99-8edc-4844-aea7-5849e672ac1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 明确指定它的输入和输出数据的结构或模式\n",
    "builder = StateGraph(OverallState, input=InputState, output=OutputState)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb09a5eb-2235-4659-9513-891f1dc535b8",
   "metadata": {},
   "source": [
    "&emsp;&emsp;创建 `builder` 对象后，相当于构建了一个图结构的框架。接下来的步骤是向这个图中添加节点和边，完善和丰富图的内部执行逻辑。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42478cd1-16ac-441a-9dc1-2e657d8722ed",
   "metadata": {},
   "source": [
    "### 3.3 Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108abf21-ae22-4723-86d6-b0c9bfde6b92",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在 `LangGraph` 中，节点是一个 `python` 函数（sync 或async ），接收当前`State`作为输入，执行自定义的计算，并返回更新的`State`。所以其中第一个位置参数是`state` 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dfffca1-ceef-40f8-b2b8-6055bb82e15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_node(state:InputState):\n",
    "    print(\"我是一个AI Agent。\")\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08e27457-7ab5-4aa3-8111-89acf7799dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_node(state:InputState):\n",
    "    print(\"我现在是一个执行者。\")\n",
    "    return {\"answer\":\"我现在执行成功了\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc29430-e1e7-4df4-9fa0-0c86f6bc0ddb",
   "metadata": {},
   "source": [
    "&emsp;&emsp;定义好了节点以后，我们需要使用`add_node`方法将这些节点添加到图中。在将节点添加到图中的时候，可以自定义节点的名称。而如果不指定名称，则会为自动指定一个与函数名称等效的默认名称。代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1bc1afb-4908-48ea-a185-17755075e16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7f2b519a1e20>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_node(\"agent_node\", agent_node)\n",
    "builder.add_node(\"action_node\", action_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f93068-a03a-467f-a100-59a8f899c5b8",
   "metadata": {},
   "source": [
    "&emsp;&emsp;现在有了图结构，并且图结构中也存在两个孤立的节点`agent_node`和`action_node`，接下来我们要做的事就是需要将图中的节点按照我们所期望的方式进行连接，这需要用到的就是`Edges` - 边。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23d79c3-c39f-43a7-9804-94787be83ef4",
   "metadata": {},
   "source": [
    "### 3.4 Edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceeaf59-9f05-4b07-b39a-d4250cc6ecb9",
   "metadata": {},
   "source": [
    "&emsp;&emsp;Edges（边）用来定义逻辑如何路由以及图何时开始与停止。这是代理工作以及不同节点如何相互通信的重要组成部分。有几种关键的边类型：\n",
    "- 普通边：直接从一个节点到下一个节点。\n",
    "- 条件边：调用函数来确定下一个要转到的节点。\n",
    "- 入口点：当用户输入到达时首先调用哪个节点。\n",
    "- 条件入口点：调用函数来确定当用户输入到达时首先调用哪个节点。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb04749e-06aa-49e5-a502-2b555d38c6b6",
   "metadata": {},
   "source": [
    "&emsp;&emsp;同样，我们先看普通边。如果直接想从节点`A`到节点`B`，可以直接使用`add_edge`方法。注意：`LangGraph`有两个特殊的节点：`START`和`END`。`START`表示将用户输入发送到图的节点。使用该节点的主要目的是确定应该首先调用哪些节点。`END`节点是代表终端节点的特殊节点。当想要指示哪些边完成后没有任何操作时，将使用该节点。因此，一个完整的图就可以使用如下代码进行定义："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1771fd62-d2e3-4296-b8f0-3773a4e6e45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7f2b519a1e20>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import START, END\n",
    "\n",
    "builder.add_edge(START, \"agent_node\")\n",
    "builder.add_edge(\"agent_node\", \"action_node\")\n",
    "builder.add_edge(\"action_node\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91518b45-0d0e-4ff4-b431-d7bc690bb2c0",
   "metadata": {},
   "source": [
    "&emsp;&emsp;最后，通过`compile`编译图。在编译过程中，会对图结构执行一些基本检查（如有没有孤立节点等）。代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba00b278-340c-43e0-a821-c9331e37c2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b7f52b-e0cd-4298-abf6-1b027935301b",
   "metadata": {},
   "source": [
    "&emsp;&emsp;至此，我们已经成功构建了一个完整的图结构，并准备好接收用户的请求。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51872848-0933-4d2e-ad5e-de8603301a64",
   "metadata": {},
   "source": [
    "### 3.5 Graph 的调用方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1de4bc2-6a20-4dfc-bb08-1308579e53a5",
   "metadata": {},
   "source": [
    "&emsp;&emsp;要调用图中的方法，可以使用 `invoke` 方法。示例代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "819ffd78-a35c-4e0d-b56a-98f91c2fba9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个AI Agent。\n",
      "我现在是一个执行者。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': '我现在执行成功了'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"question\":\"hello，你好\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fae40457-64d7-445f-a143-2bde4d2ddd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个AI Agent。\n",
      "我现在是一个执行者。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': '我现在执行成功了'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"question\":\"今天的天气怎么样？\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6707ec16-6dda-4cd1-aaf5-8e812be47800",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在这个过程中，我们将`state: InputState`作为输入模式传递给`agent_node`，在传递到`action_node`，最后由`action_node`传递到`END`节点。节点之间通过边是已经构建了完整的通路，那么如果我们想要传递每个节点的状态信息，则可以稍加修改即可实现。对于图模式，我们的定义方法如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bdd7054-8c05-4633-855f-7b40b21ceff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import START, END\n",
    "\n",
    "# 定义输入的模式\n",
    "class InputState(TypedDict):\n",
    "    question: str\n",
    "\n",
    "\n",
    "# 定义输出的模式\n",
    "class OutputState(TypedDict):\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# 将 InputState 和 OutputState 这两个 TypedDict 类型合并成一个更全面的字典类型。\n",
    "class OverallState(InputState, OutputState):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d605e238-0854-4b9c-ac5c-a8d693348fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_node(state: InputState):\n",
    "    print(\"我是一个AI Agent。\")\n",
    "    return {\"question\": state[\"question\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae4b9e38-c5e4-4de0-8508-fb606affc60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_node(state: InputState):\n",
    "    print(\"我现在是一个执行者。\")\n",
    "    step = state[\"question\"]\n",
    "    return {\"answer\": f\"我接收到的问题是：{step}，读取成功了！\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01f648e1-7c7c-488d-ba8d-d54dae4c3591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 明确指定它的输入和输出数据的结构或模式\n",
    "builder = StateGraph(OverallState, input=InputState, output=OutputState)\n",
    "\n",
    "# 添加节点\n",
    "builder.add_node(\"agent_node\", agent_node)\n",
    "builder.add_node(\"action_node\", action_node)\n",
    "\n",
    "# 添加边\n",
    "builder.add_edge(START, \"agent_node\")\n",
    "builder.add_edge(\"agent_node\", \"action_node\")\n",
    "builder.add_edge(\"action_node\", END)\n",
    "\n",
    "# 编译图\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3024760d-74cb-4b95-a31f-cf60b37113dc",
   "metadata": {},
   "source": [
    "&emsp;&emsp;执行调用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ab4f5a2-d487-4f00-9152-28f13173e539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个AI Agent。\n",
      "我现在是一个执行者。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': '我接收到的问题是：今天的天气怎么样？，读取成功了！'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"question\":\"今天的天气怎么样？\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8f7c498-a48f-418c-af20-2255db8cd40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个AI Agent。\n",
      "我现在是一个执行者。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': '我接收到的问题是：你好，我用来测试，读取成功了！'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"question\":\"你好，我用来测试\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbefd3a-bb8a-4b9b-97ae-0bcbe1ff3668",
   "metadata": {},
   "source": [
    "&emsp;&emsp;不同节点间能够传递信息的原因是因为节点可以写入图状态中的任何状态通道。图状态是初始化时定义的状态通道的并集，而我们定义的状态通道包含了`OverallState`以及过滤器`InputState`和`OutputState` 。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1b2044-f921-4e59-a7c2-08dd94cd11aa",
   "metadata": {},
   "source": [
    "## 4. 使用LangGraph构建大模型的问答流程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7507ac-bedc-41f1-a1ad-ae03b6319fa9",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在上面的示例中，我们通过使用打印函数来初步了解`LangGraph`构建图的基本方法和机制。接下来，我们将探索如何将大模型集成至`LangGraph`框架中，从而构建一个更具实际应用价值的用于问答流程的图模式。\n",
    "\n",
    "&emsp;&emsp;首先，`LangGraph`对目前主流的在线或者开源模型均支持接入，所以大家可以在该框架下非常便捷的应用到自己偏爱的大模型来进行问答流程的构建。这下面的示例中，我们选择比较方便且高效的`LangChain`框架，同时使用`OpenAI`的`GPT`模型来进行案例实现。而关于`LangChain`支持接入的模型列表及方式，大家可以在`LangChain Docs`中查阅：https://python.langchain.com/docs/integrations/chat/ 或者 https://python.langchain.com/docs/integrations/llms/ 。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fde796-b95e-4279-980e-431823edf1a8",
   "metadata": {},
   "source": [
    "&emsp;&emsp;这里仍然需要首先定义图模式，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b5423eb-7bc4-48eb-9646-220786fc8bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import START, END\n",
    "\n",
    "# 定义输入的模式\n",
    "class InputState(TypedDict):\n",
    "    question: str\n",
    "\n",
    "# 定义输出的模式\n",
    "class OutputState(TypedDict):\n",
    "    answer: str\n",
    "\n",
    "# 将 InputState 和 OutputState 这两个 TypedDict 类型合并成一个更全面的字典类型。\n",
    "class OverallState(InputState, OutputState):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af858d88-662b-4e26-ad77-cf3f3e37b0c7",
   "metadata": {},
   "source": [
    "&emsp;&emsp;使用`OpenAI`的`GPT`模型需要使用到`ChatOpenAI`方法，我们需要将其定义到`Agent`节点中，用来接收用户输入的问题，调用`GPT`模型来根据用户的问题生成自然语言的回复响应。代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed83c542-33cc-4053-8176-03b63071af86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def llm_node(state: InputState):\n",
    "    messages = [\n",
    "        (\"system\",\"你是一位乐于助人的智能小助理\",),\n",
    "        (\"human\", state[\"question\"])\n",
    "    ]\n",
    "\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", api_key=key,base_url=base_url,temperature=0,)\n",
    "\n",
    "    response = llm.invoke(messages) \n",
    "\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36673be-d306-4616-b390-4c23565a8d02",
   "metadata": {},
   "source": [
    "&emsp;&emsp;构建图，添加节点和边，并进行图结构的编译。完整代码如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35862fe9-eb90-484a-a275-b7836519b431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 明确指定它的输入和输出数据的结构或模式\n",
    "builder = StateGraph(OverallState, input=InputState, output=OutputState)\n",
    "\n",
    "# 添加节点\n",
    "builder.add_node(\"llm_node\", llm_node)\n",
    "\n",
    "# 添加边\n",
    "builder.add_edge(START, \"llm_node\")\n",
    "builder.add_edge(\"llm_node\", END)\n",
    "\n",
    "# 编译图\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959a6a73-9814-4ba3-8045-467b340b927d",
   "metadata": {},
   "source": [
    "&emsp;&emsp;进行测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "465b2f72-df96-45ae-8366-a8567379c88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': '你好！如果有任何问题或者需要帮助的地方，请随时告诉我。'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"question\":\"你好，我用来测试\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccc260a8-e77d-4c3a-91c7-d3d5fb5e9352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！如果你有任何问题或者需要帮助，请随时告诉我。测试进行得怎么样？\n"
     ]
    }
   ],
   "source": [
    "final_answer = graph.invoke({\"question\":\"你好，我用来测试\"})\n",
    "\n",
    "print(final_answer[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "365d29bb-9f2b-40c5-af2a-7a30b172d242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！我是一个人工智能助手，设计目的是帮助用户处理各种任务和回答问题。我可以提供信息和支持，涵盖从基础的日常问询到复杂的问题解决。我的目标是以最清晰和有效的方式满足你的需求。以下是一些我可以帮助你的方面：\n",
      "\n",
      "1. **信息查询**：我可以提供最新的新闻、天气预报、百科知识和常见问题解答。\n",
      "\n",
      "2. **任务管理**：如果你需要，我可以帮助你制定计划、设置提醒或管理待办事项。\n",
      "\n",
      "3. **学习和教育**：我能帮助解释复杂的概念，提供学习资源，或陪伴你一起练习一些学习任务。\n",
      "\n",
      "4. **技术支持**：我可以回答关于软件、硬件和其它技术问题的常见问题。\n",
      "\n",
      "5. **语言和翻译**：我能帮助进行基本的语言翻译和纠正语言错误。\n",
      "\n",
      "6. **娱乐和建议**：我也可以推荐电影、书籍、音乐，以及提供一些轻松有趣的话题或游戏。\n",
      "\n",
      "请随时告诉我，你需要什么样的帮助！\n"
     ]
    }
   ],
   "source": [
    "final_answer = graph.invoke({\"question\":\"你好，请你详细的介绍一下你自己\"})\n",
    "\n",
    "print(final_answer[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9278a146-0ba1-4efe-b653-938974f0fdf8",
   "metadata": {},
   "source": [
    "&emsp;&emsp;更进一步地，如果想在原有的图结构中构建更复杂的功能，则只需要新定义一个`Python`函数，并按照自己的预期流程用边来建立连接，如下代码所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6172ee5-9f49-4718-9f3b-54f88f03cc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from typing_extensions import TypedDict, Optional\n",
    "from langgraph.graph import START, END\n",
    "\n",
    "# 定义输入的模式\n",
    "class InputState(TypedDict):\n",
    "    question: str\n",
    "    llm_answer: Optional[str]  # 表示 answer 可以是 str 类型，也可以是 None\n",
    "\n",
    "\n",
    "# 定义输出的模式\n",
    "class OutputState(TypedDict):\n",
    "    answer: str\n",
    "\n",
    "# 将 InputState 和 OutputState 这两个 TypedDict 类型合并成一个更全面的字典类型。\n",
    "class OverallState(InputState, OutputState):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1181a6-36c4-4d20-b31d-97ce5835450c",
   "metadata": {},
   "source": [
    "&emsp;&emsp;我们定义了一个`action_node`节点，用来接收`llm_node`的输出，将其翻译成中文，如下代码所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a408462a-9e55-47a4-912f-f79388cb7844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_node(state: InputState):\n",
    "    messages = [\n",
    "        (\"system\",\"你是一位乐于助人的智能小助理\",),\n",
    "        (\"human\", state[\"question\"])\n",
    "    ]\n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", api_key=key,base_url=base_url,temperature=0,)\n",
    "    response = llm.invoke(messages) \n",
    "\n",
    "    return {\"llm_answer\": response.content}\n",
    "\n",
    "def action_node(state: InputState):\n",
    "    messages = [\n",
    "        (\"system\",\"无论你接收到什么语言的文本，请翻译成英语\",),\n",
    "        (\"human\", state[\"llm_answer\"])\n",
    "    ]\n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", api_key=key,base_url=base_url,temperature=0,)\n",
    "\n",
    "    response = llm.invoke(messages) \n",
    "\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0796bf-13ef-4e77-9d69-25d12e73940f",
   "metadata": {},
   "source": [
    "&emsp;&emsp;构建图，添加节点和边，并进行图结构的编译。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4ca898f-3fe3-4a2e-9523-a54386b82552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 明确指定它的输入和输出数据的结构或模式\n",
    "builder = StateGraph(OverallState, input=InputState, output=OutputState)\n",
    "\n",
    "# 添加节点\n",
    "builder.add_node(\"llm_node\", llm_node)\n",
    "builder.add_node(\"action_node\", action_node)\n",
    "\n",
    "\n",
    "# 添加便\n",
    "builder.add_edge(START, \"llm_node\")\n",
    "builder.add_edge(\"llm_node\", \"action_node\")\n",
    "builder.add_edge(\"action_node\", END)\n",
    "\n",
    "# 编译图\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05089893-aed3-4d2f-9751-b07e3ea2cb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I am your intelligent assistant, designed to provide you with various information and help. I don't have a specific name, but you can call me whatever you like. I am developed based on advanced artificial intelligence technology, capable of processing and understanding multiple languages, and offering support on a wide range of topics.\n",
      "\n",
      "My main functions include:\n",
      "\n",
      "1. **Information Retrieval**: I can help you search for and provide information on almost any topic, whether it's science, history, technology, or everyday life questions.\n",
      "\n",
      "2. **Task Assistance**: I can assist with reminders, calendar management, and planning tasks to help you better organize your daily life.\n",
      "\n",
      "3. **Language Translation**: I can translate between multiple languages to help you overcome language barriers.\n",
      "\n",
      "4. **Education and Learning**: Whether it's academic research or personal study, I can provide materials and recommend resources.\n",
      "\n",
      "5. **Creativity and Entertainment**: I can assist with creative writing, provide entertainment suggestions, and even engage in some interesting conversations.\n",
      "\n",
      "6. **Technical Support**: I can solve basic technical problems and guide you through some simple troubleshooting.\n",
      "\n",
      "7. **Health and Lifestyle Advice**: Based on general knowledge, I can offer some lifestyle and health advice, though I'm not a professional medical or psychological health advisor.\n",
      "\n",
      "Please feel free to let me know what kind of help you need, and I'll do my best to support you!\n"
     ]
    }
   ],
   "source": [
    "final_answer = graph.invoke({\"question\":\"你好，请你详细的介绍一下你自己\"})\n",
    "\n",
    "print(final_answer[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8617ccc2-185c-4f1d-a882-9a14e05f50ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence (AI) is a branch of computer science focused on creating computer systems capable of performing tasks that typically require human intelligence. These tasks include, but are not limited to, visual perception, speech recognition, decision-making, and language translation. AI achieves these capabilities by mimicking human learning and thinking processes, often using algorithms, big data, and computational power.\n",
      "\n",
      "AI can be categorized into several types:\n",
      "\n",
      "1. **Narrow AI (ANI)**: Also known as weak AI, it focuses on specific tasks, such as voice assistants or chess game algorithms.\n",
      "\n",
      "2. **General AI (AGI)**: Also known as strong AI, it refers to systems capable of understanding, learning, and applying knowledge across various fields, similar to human intelligence. Although not yet achieved, it remains a goal in AI development.\n",
      "\n",
      "3. **Superintelligent AI (ASI)**: A hypothetical form of AI that surpasses human intelligence and has the ability to independently improve and optimize itself. This stage currently remains a concept in science fiction.\n",
      "\n",
      "AI technology is widely applied across various industries, including autonomous vehicles, medical diagnosis, financial analysis, personalized recommendation systems, and robotics.\n"
     ]
    }
   ],
   "source": [
    "final_answer = graph.invoke({\"question\":\"请问什么是人工智能？\"})\n",
    "\n",
    "print(final_answer[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806a77af-b45f-476d-95b4-7be91819c0cb",
   "metadata": {},
   "source": [
    "&emsp;&emsp;深入理解 `LangGraph` 的底层原理及其基于图结构的构建逻辑后，可以明显感受到，相较于 `LangChain` 的 `AI Agent` 架构，`LangGraph` 展现出了更高的灵活性和可扩展性。在 `LangGraph` 中，我们能够通过各个 `Python` 函数定义节点的核心逻辑，并通过边来确定输入和输出的关系。此外，节点函数在定义时还可以自主生成和管理中间状态的信息。虽然在本示例中，我们通过 `LangChain` 实现大模型的接入，但从节点函数的定义逻辑来看，完全可以不依赖 `LangChain`，而采用原生方法完成接入。\n",
    "\n",
    "由此可见，正如课程开始时所强调的，**尽管 `LangGraph` 基于 `LangChain` 表达式语言构建，但它完全具备独立运行的能力。** 整体而言，今天的示例虽然并不复杂，但涉及的知识点和细节较为丰富。建议大家亲自实践，通过动手操作巩固基础，为后续复杂循环图的学习打下坚实的基础。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6122031c-41db-4bc8-b288-80c3ed72dc20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
